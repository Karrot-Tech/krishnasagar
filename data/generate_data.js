// data/generate_data.js

const fs = require('fs');
const path = require('path');

// ==== Configuration ==== //
const RAW_DATA_PATH = path.resolve(__dirname, 'raw-upstream-data/yt-transcripts-data.json');
const OUTPUT_PATH = path.resolve(__dirname, '../generated_data.json');

// Load raw data
let rawData;
try {
    rawData = JSON.parse(fs.readFileSync(RAW_DATA_PATH, 'utf-8'));
} catch (e) {
    console.error('Failed to read raw data:', e);
    process.exit(1);
}

// Helper to extract YouTube video ID from URL
function extractYouTubeId(url) {
    const match = url.match(/[?&]v=([^&#]+)/);
    return match ? match[1] : null;
}

// Simple classification based on title / tags
function classify(entry) {
    const title = entry.Title?.toLowerCase() || '';
    const tags = (entry.Tags || '').toLowerCase();
    if (/chapter\s*\d+/.test(title) || /chapter\s*\d+/.test(tags)) {
        return 'chapters';
    }
    if (tags.includes('leela') || title.includes('leela')) {
        return 'leela_articles';
    }
    if (tags.includes('bodhakatha') || title.includes('bodhakatha')) {
        return 'bodhakatha_articles';
    }
    return 'glossary';
}

// Placeholder LLM call – replace with actual API integration
async function generateWithLLM(prompt) {
    // For now we return a mock response; in production hook into OpenAI/Vertex AI etc.
    // Example prompt could ask for Hindi title, English title, short description, keywords, social tags.
    // The function returns an object with the expected fields.
    return {
        title_en: 'Generated English Title',
        title_hi: 'Generated Hindi Title',
        description: 'Short description generated by LLM.',
        keywords: ['keyword1', 'keyword2', 'keyword3'],
        social_tags: ['#SaiBaba', '#Spirituality']
    };
}

async function processEntry(entry) {
    const category = classify(entry);
    const youtubeId = extractYouTubeId(entry.URL) || '';
    const base = {
        youtube_id: youtubeId,
        url: entry.URL,
        original_title: entry.Title,
        original_description: entry.Description,
        tags_raw: entry.Tags
    };

    // Build a prompt for the LLM – you can tailor this to the schema you need.
    const prompt = `Generate structured data for a ${category.replace('_', ' ')} based on the following information:\n` +
        `Title: ${entry.Title}\n` +
        `Description: ${entry.Description}\n` +
        `Tags: ${entry.Tags}\n` +
        `Provide: English title, Hindi title, short description (2-3 sentences), 5 SEO keywords, and 3 social‑media hashtags.`;

    const llmResult = await generateWithLLM(prompt);

    // Merge base with LLM result
    return { ...base, ...llmResult };
}

(async () => {
    const result = {
        source: 'data/raw-upstream-data/yt-transcripts-data.json',
        chapters: [],
        leela_articles: [],
        bodhakatha_articles: [],
        glossary: []
    };

    for (const entry of rawData) {
        try {
            const processed = await processEntry(entry);
            const cat = classify(entry);
            result[cat].push(processed);
        } catch (e) {
            console.warn('Failed to process entry:', entry.Title, e);
        }
    }

    // Write output
    fs.writeFileSync(OUTPUT_PATH, JSON.stringify(result, null, 2), 'utf-8');
    console.log('Generated data written to', OUTPUT_PATH);
})();
